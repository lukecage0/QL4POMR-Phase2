{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BertTokenizer, BertForMaskedLM\nimport torch\n\ndef read_input_file(file_path):\n    with open(file_path, 'r') as file:\n        return file.read().strip()\n\ndef generate_summary(prompt, model_name=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\", max_length=512):\n    tokenizer = BertTokenizer.from_pretrained(model_name)\n    model = BertForMaskedLM.from_pretrained(model_name)\n    \n    prompt = \"Summary: \" + prompt\n    \n    input_ids = tokenizer.encode(prompt, return_tensors='pt', truncation=True, max_length=max_length)\n    \n    # Generate a response using the model\n    with torch.no_grad():\n        outputs = model(input_ids)\n        predictions = outputs.logits\n\n    # Just get the predicted tokens for now, it's hacky but might provide a compressed form of the content\n    predicted_ids = torch.argmax(predictions, dim=2)\n    summary = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n\n    return summary\n\nif __name__ == \"__main__\":\n    file_path = \"/kaggle/input/full-texts/Abstract-2529.txt\"\n    input_text = read_input_file(file_path)\n    generated_summary = generate_summary(input_text)\n    print(generated_summary)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-04T23:59:23.084538Z","iopub.execute_input":"2023-09-04T23:59:23.085006Z","iopub.status.idle":"2023-09-04T23:59:26.093027Z","shell.execute_reply.started":"2023-09-04T23:59:23.084957Z","shell.execute_reply":"2023-09-04T23:59:26.091761Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"##s summary : we report a rare case of immunoglobulin g4 ( igg4 ) - related sclerosing cholangitis without other organ involvement. a 69 - year - old - man was referred for the evaluation of jaundice. computed tomography revealed thickening of the bile duct wall, compressing the right portal vein. endoscopic retrograde cholangiopancreatography showed a lesion extending from the proximal confluence of the common bile duct to the left and right hepatic ducts. intraductal ultrasonography showed a bile duct mass invading the portal vein. hilar bile duct cancer was initially diagnosed and percutaneous transhepatic portal vein embolization was performed, preceding a planned right hepatectomy. strictures persisted despite steroid therapy. therefore, partial resection of the common bile duct following choledochojejunostomy was performed. histologic examination showed diffuse and severe lymphoplasmacytic infiltration, and abundant plasma cells, which stained positive for anti - igg4 antibody. the final diagnosis was igg4 sclerosing cholangitis. types 3 and 4 igg4 sclerosing cholangitis remains a challenge to differentiate from cholangiocarcinoma. a histopathologic diagnosis obtained with a less invasive approach avoided unnecessary hepatectomy..\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install rouge-score","metadata":{"execution":{"iopub.status.busy":"2023-09-04T23:59:28.589753Z","iopub.execute_input":"2023-09-04T23:59:28.590211Z","iopub.status.idle":"2023-09-04T23:59:41.831175Z","shell.execute_reply.started":"2023-09-04T23:59:28.590177Z","shell.execute_reply":"2023-09-04T23:59:41.829725Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge-score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.23.5)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from rouge_score import rouge_scorer\n\ndef compute_rouge(reference, candidate):\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True)\n    scores = scorer.score(reference, candidate)\n    return scores\n\nif __name__ == '__main__':\n    file_path = \"/kaggle/input/full-texts/Abstract-2529.txt\"\n    input_abstract = read_input_file(file_path)\n    reference =  input_abstract  \n    candidate = generated_summary\n\n    scores = compute_rouge(reference, candidate)\n    for key, score in scores.items():\n        print(f\"{key.upper()}:\")\n        print(f\"  Precision: {score.precision:.4f}\")\n        print(f\"  Recall: {score.recall:.4f}\")\n        print(f\"  F1 Score: {score.fmeasure:.4f}\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:00:46.983522Z","iopub.execute_input":"2023-09-05T00:00:46.984098Z","iopub.status.idle":"2023-09-05T00:00:47.076335Z","shell.execute_reply.started":"2023-09-05T00:00:46.984054Z","shell.execute_reply":"2023-09-05T00:00:47.075211Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"ROUGE1:\n  Precision: 0.9880\n  Recall: 1.0000\n  F1 Score: 0.9940\n\nROUGE2:\n  Precision: 0.9880\n  Recall: 1.0000\n  F1 Score: 0.9939\n\nROUGEL:\n  Precision: 0.9880\n  Recall: 1.0000\n  F1 Score: 0.9940\n\nROUGELSUM:\n  Precision: 0.9880\n  Recall: 1.0000\n  F1 Score: 0.9940\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForQuestionAnswering\n\nMODEL_NAME_OR_PATH = \"dmis-lab/biobert-base-cased-v1.1-squad\"\n\ntokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\nmodel = BertForQuestionAnswering.from_pretrained(MODEL_NAME_OR_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T16:05:01.904726Z","iopub.execute_input":"2023-09-05T16:05:01.905164Z","iopub.status.idle":"2023-09-05T16:05:40.356587Z","shell.execute_reply.started":"2023-09-05T16:05:01.905128Z","shell.execute_reply":"2023-09-05T16:05:40.355165Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4e9c88ca245495b9c62e962c26639a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/477 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2efecd83ed16455994ac749dd2619788"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5f7eebc28cd4b35b853c0e0cae3103e"}},"metadata":{}}]},{"cell_type":"code","source":"# 3. Define a function to perform question-answering using BioBERT.\ndef answer_question(question, context):\n    inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"].tolist()[0]\n\n    outputs = model(**inputs)\n    answer_start_scores = outputs.start_logits\n    answer_end_scores = outputs.end_logits\n\n    answer_start = torch.argmax(answer_start_scores)  \n    answer_end = torch.argmax(answer_end_scores) + 1 \n\n    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n\n    return answer\n\n# 4. Use the function to ask questions.\ncontext = generated_summary\nquestion = \"what is the age of the man\"\n\nprint(answer_question(question, context))","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:01:34.672318Z","iopub.execute_input":"2023-09-05T00:01:34.672734Z","iopub.status.idle":"2023-09-05T00:01:35.322095Z","shell.execute_reply.started":"2023-09-05T00:01:34.672703Z","shell.execute_reply":"2023-09-05T00:01:35.320871Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"69\n","output_type":"stream"}]}]}