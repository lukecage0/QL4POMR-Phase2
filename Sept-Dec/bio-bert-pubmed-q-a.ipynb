{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BertTokenizer, BertForMaskedLM\nimport torch\nfrom datasets import load_dataset\n\ndef read_input_file(file_path):\n    with open(file_path, 'r') as file:\n        return file.read().strip()\n\ndef generate_summary(prompt, model_name=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\", max_length=512):\n    tokenizer = BertTokenizer.from_pretrained(model_name)\n    model = BertForMaskedLM.from_pretrained(model_name)\n    \n    prompt = \"Summary: \" + prompt\n    \n    input_ids = tokenizer.encode(prompt, return_tensors='pt', truncation=True, max_length=max_length)\n    \n    # Generate a response using the model\n    with torch.no_grad():\n        outputs = model(input_ids)\n        predictions = outputs.logits\n\n    # Just get the predicted tokens for now, it's hacky but might provide a compressed form of the content\n    predicted_ids = torch.argmax(predictions, dim=2)\n    summary = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n\n    return summary\n\nif __name__ == \"__main__\":\n    file_path = \"/kaggle/input/full-texts/Abstract-2529.txt\"\n    input_text = read_input_file(file_path)\n    generated_summary = generate_summary(input_text)\n    print(generated_summary)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-05T22:23:08.885387Z","iopub.execute_input":"2023-10-05T22:23:08.885777Z","iopub.status.idle":"2023-10-05T22:23:53.040737Z","shell.execute_reply.started":"2023-10-05T22:23:08.885738Z","shell.execute_reply":"2023-10-05T22:23:53.039653Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/225k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"999c95ebb0a74814a6c8e27714c41a37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bcad36bc3ba4b77989895469aaf6eb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03666d11b41a45a4ad1bd55f9e1dbc36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7748385a1f3b4f22ba3bb616c027a6e6"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"##s summary : we report a rare case of immunoglobulin g4 ( igg4 ) - related sclerosing cholangitis without other organ involvement. a 69 - year - old - man was referred for the evaluation of jaundice. computed tomography revealed thickening of the bile duct wall, compressing the right portal vein. endoscopic retrograde cholangiopancreatography showed a lesion extending from the proximal confluence of the common bile duct to the left and right hepatic ducts. intraductal ultrasonography showed a bile duct mass invading the portal vein. hilar bile duct cancer was initially diagnosed and percutaneous transhepatic portal vein embolization was performed, preceding a planned right hepatectomy. strictures persisted despite steroid therapy. therefore, partial resection of the common bile duct following choledochojejunostomy was performed. histologic examination showed diffuse and severe lymphoplasmacytic infiltration, and abundant plasma cells, which stained positive for anti - igg4 antibody. the final diagnosis was igg4 sclerosing cholangitis. types 3 and 4 igg4 sclerosing cholangitis remains a challenge to differentiate from cholangiocarcinoma. a histopathologic diagnosis obtained with a less invasive approach avoided unnecessary hepatectomy..\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install rouge-score","metadata":{"execution":{"iopub.status.busy":"2023-10-05T22:23:53.043180Z","iopub.execute_input":"2023-10-05T22:23:53.044700Z","iopub.status.idle":"2023-10-05T22:24:06.364221Z","shell.execute_reply.started":"2023-10-05T22:23:53.044650Z","shell.execute_reply":"2023-10-05T22:24:06.363048Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.23.5)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=a8177857c55417188b02a4628239cee90c7f897d7f972904b6ce6e3e9c25aeaf\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from rouge_score import rouge_scorer\n\ndef compute_rouge(reference, candidate):\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True)\n    scores = scorer.score(reference, candidate)\n    return scores\n\nif __name__ == '__main__':\n    file_path = \"/kaggle/input/full-texts/Abstract-2529.txt\"\n    input_abstract = read_input_file(file_path)\n    reference =  input_abstract  \n    candidate = generated_summary\n\n    scores = compute_rouge(reference, candidate)\n    for key, score in scores.items():\n        print(f\"{key.upper()}:\")\n        print(f\"  Precision: {score.precision:.4f}\")\n        print(f\"  Recall: {score.recall:.4f}\")\n        print(f\"  F1 Score: {score.fmeasure:.4f}\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-10-05T22:24:06.366544Z","iopub.execute_input":"2023-10-05T22:24:06.366895Z","iopub.status.idle":"2023-10-05T22:24:07.278680Z","shell.execute_reply.started":"2023-10-05T22:24:06.366863Z","shell.execute_reply":"2023-10-05T22:24:07.277660Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"ROUGE1:\n  Precision: 0.9880\n  Recall: 1.0000\n  F1 Score: 0.9940\n\nROUGE2:\n  Precision: 0.9880\n  Recall: 1.0000\n  F1 Score: 0.9939\n\nROUGEL:\n  Precision: 0.9880\n  Recall: 1.0000\n  F1 Score: 0.9940\n\nROUGELSUM:\n  Precision: 0.9880\n  Recall: 1.0000\n  F1 Score: 0.9940\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForQuestionAnswering\n\nMODEL_NAME_OR_PATH = \"dmis-lab/biobert-base-cased-v1.1-squad\"\n\ntokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\nmodel = BertForQuestionAnswering.from_pretrained(MODEL_NAME_OR_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T22:24:07.280014Z","iopub.execute_input":"2023-10-05T22:24:07.280367Z","iopub.status.idle":"2023-10-05T22:24:35.650288Z","shell.execute_reply.started":"2023-10-05T22:24:07.280341Z","shell.execute_reply":"2023-10-05T22:24:35.649544Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eb45e4941b443d2b3a9654749a5ebcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/477 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eb3cddc92f04c0d8ca77de61d7027a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21a00d7dd4734a9488cbb5a6128c610b"}},"metadata":{}}]},{"cell_type":"code","source":"# 3. Define a function to perform question-answering using BioBERT.\ndef answer_question(question, context):\n    inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"].tolist()[0]\n\n    outputs = model(**inputs)\n    answer_start_scores = outputs.start_logits\n    answer_end_scores = outputs.end_logits\n\n    answer_start = torch.argmax(answer_start_scores)  \n    answer_end = torch.argmax(answer_end_scores) + 1 \n\n    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n\n    return answer\n\n# 4. Use the function to ask questions.\ncontext = generated_summary\nquestion = \"give diagnosis\"\n\nanswer= answer_question(question, context)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T22:24:35.652045Z","iopub.execute_input":"2023-10-05T22:24:35.652905Z","iopub.status.idle":"2023-10-05T22:24:36.244144Z","shell.execute_reply.started":"2023-10-05T22:24:35.652876Z","shell.execute_reply":"2023-10-05T22:24:36.243429Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(\"Question: \"+question)\nprint(\"Context: \"+ context)\nprint(\"Answer: \"+ answer )","metadata":{"execution":{"iopub.status.busy":"2023-10-05T22:24:36.245534Z","iopub.execute_input":"2023-10-05T22:24:36.246168Z","iopub.status.idle":"2023-10-05T22:24:36.252341Z","shell.execute_reply.started":"2023-10-05T22:24:36.246129Z","shell.execute_reply":"2023-10-05T22:24:36.251184Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Question: give diagnosis\nContext: ##s summary : we report a rare case of immunoglobulin g4 ( igg4 ) - related sclerosing cholangitis without other organ involvement. a 69 - year - old - man was referred for the evaluation of jaundice. computed tomography revealed thickening of the bile duct wall, compressing the right portal vein. endoscopic retrograde cholangiopancreatography showed a lesion extending from the proximal confluence of the common bile duct to the left and right hepatic ducts. intraductal ultrasonography showed a bile duct mass invading the portal vein. hilar bile duct cancer was initially diagnosed and percutaneous transhepatic portal vein embolization was performed, preceding a planned right hepatectomy. strictures persisted despite steroid therapy. therefore, partial resection of the common bile duct following choledochojejunostomy was performed. histologic examination showed diffuse and severe lymphoplasmacytic infiltration, and abundant plasma cells, which stained positive for anti - igg4 antibody. the final diagnosis was igg4 sclerosing cholangitis. types 3 and 4 igg4 sclerosing cholangitis remains a challenge to differentiate from cholangiocarcinoma. a histopathologic diagnosis obtained with a less invasive approach avoided unnecessary hepatectomy..\nAnswer: rare case of immunoglobulin g4 ( igg4 ) - related sclerosing cholangitis\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = load_dataset('pubmed_qa', 'pqa_labeled')","metadata":{"execution":{"iopub.status.busy":"2023-10-05T22:24:36.253910Z","iopub.execute_input":"2023-10-05T22:24:36.254523Z","iopub.status.idle":"2023-10-05T22:24:53.198837Z","shell.execute_reply.started":"2023-10-05T22:24:36.254483Z","shell.execute_reply":"2023-10-05T22:24:53.197444Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/3.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f9186bb626640e284fdc7351e738da5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/2.25k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2dfd9c5b4c746d4a3ea726e0e1ac942"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset pubmed_qa/pqa_labeled (download: 656.02 MiB, generated: 1.99 MiB, post-processed: Unknown size, total: 658.01 MiB) to /root/.cache/huggingface/datasets/pubmed_qa/pqa_labeled/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"883a45c87d2348c4a93ec901486e9f17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/709k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34d115a1b51d4befadda0815728dbf90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/152M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a0d0d4fdf564fcdb2202e005a3fd7bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/533M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"373778c135ce4058bfee4b6dad52aee7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"045d9ceba4b44916b3d571477d896812"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset pubmed_qa downloaded and prepared to /root/.cache/huggingface/datasets/pubmed_qa/pqa_labeled/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7271f927abb34b4e8d2a90835352546f"}},"metadata":{}}]},{"cell_type":"code","source":"total_f1, total_exact = 0, 0\n\nfor sample in dataset['train']:\n    question = sample['question']\n    context = sample['context']['contexts']\n    correct_answer = sample['long_answer']\n\n    # Encode and get model's prediction\n    inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\", max_length=512, truncation=True)\n    input_ids = inputs[\"input_ids\"].tolist()[0]\n    \n    with torch.no_grad():\n        output = model(**inputs)\n    \n    # Extract answer\n    answer_start = torch.argmax(output.start_logits)\n    answer_end = torch.argmax(output.end_logits) + 1\n    pred_answer = tokenizer.decode(input_ids[answer_start:answer_end])\n\n    # Compute F1 and Exact match\n    common = set(pred_answer.lower().split()) & set(correct_answer.lower().split())\n    f1 = 2 * len(common) / (len(pred_answer.split()) + len(correct_answer.split()))\n    total_f1 += f1\n\n    if pred_answer.lower() == correct_answer.lower():\n        total_exact += 1\n\n# Average F1 and Exact match\navg_f1 = total_f1 / len(dataset['train'])\navg_exact = total_exact / len(dataset['train'])\n\nprint(f\"Average F1 Score: {avg_f1}\")\nprint(f\"Exact Match: {avg_exact}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-05T22:29:58.002352Z","iopub.execute_input":"2023-10-05T22:29:58.002747Z","iopub.status.idle":"2023-10-05T22:31:18.101896Z","shell.execute_reply.started":"2023-10-05T22:29:58.002717Z","shell.execute_reply":"2023-10-05T22:31:18.100853Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Average F1 Score: 0.08838785016297217\nExact Match: 0.0\n","output_type":"stream"}]}]}